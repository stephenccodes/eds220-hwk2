{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hwk2-task2-salmon.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Wrangling Alaska salmon catch data \n",
    "\n",
    "## Instructions \n",
    "\n",
    "- First, update the following cell to have a link to *your* Homework 2 GitHub repository:\n",
    "\n",
    "https://github.com/stephenccodes/eds220-hwk2.git\n",
    "\n",
    "- Review the [complete rubric for this task](https://docs.google.com/document/d/1x0BoU6IH4cnOR1-n7i9CYQ9wUC37yDpYlQ4j6rCfcsU/edit?tab=t.0) before starting.\n",
    "\n",
    "- **Meaningful commits should be made every time you finish a major step.** We'll check your repository and view the commit history.\n",
    "\n",
    "- **Every code cell should have a comment.** Err on the side of commenting too much for now. Comments should follow best practices.\n",
    "\n",
    "- **Do not update the top cell with the `otter` import**, this is used internally for grading.\n",
    "\n",
    "## Acknowledgments\n",
    "\n",
    "This exercise is based on the [Cleaning and Wrangling Data in R lesson by the NCEAS Learning Hub](https://learning.nceas.ucsb.edu/2023-06-delta/session_11.html).\n",
    "\n",
    "\n",
    "> Halina Do-Linh, Carmen Galaz GarcÃ­a, Matthew B. Jones, Camila Vargas Poulsen. 2023. Open Science Synthesis training Week 1. NCEAS Learning Hub & Delta Stewardship Council.\n",
    "\n",
    "\n",
    "## About the data\n",
    "\n",
    "In this task you will use simplified data from the Alaska Department of Fish & Game containing commercial salmon catch data from 1878 to 1997. The original data can be accessed from the KNB repository:\n",
    "\n",
    "> [Mike Byerly. (2016). Alaska commercial salmon catches by management region (1886-1997).](https://knb.ecoinformatics.org/view/df35b.304.2) Gulf of Alaska Data Portal. df35b.304.2.\n",
    "\n",
    "The simplified dataset is in CSV format in the homework repository and has the following columns:\n",
    "\n",
    "| Column | Description |\n",
    "| ------ | ----------- | \n",
    "| Regions | Region code |\n",
    "| Year | Year fish were caught |\n",
    "| notesRegCode | Notes and comments |\n",
    "| Species | Species of salmon caught |\n",
    "| Catch | Commercial catches of salmon species (in thousands of fish) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPLETE WORKFLOW\n",
    "\n",
    "You will use the next code cell to complete the last exercise in the task. Leave it blank for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL CODE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "a. Uset this code cell to import the data from the `salmon_data.csv` as `catch_data`. Look at the head of the dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Year</th>\n",
       "      <th>Chinook</th>\n",
       "      <th>Sockeye</th>\n",
       "      <th>Coho</th>\n",
       "      <th>Pink</th>\n",
       "      <th>Chum</th>\n",
       "      <th>All</th>\n",
       "      <th>notesRegCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SSE</td>\n",
       "      <td>1886</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SSE</td>\n",
       "      <td>1887</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SSE</td>\n",
       "      <td>1888</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SSE</td>\n",
       "      <td>1889</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>11</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>285</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SSE</td>\n",
       "      <td>1890</td>\n",
       "      <td>0</td>\n",
       "      <td>251</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Region  Year Chinook  Sockeye  Coho  Pink  Chum  All notesRegCode\n",
       "0    SSE  1886       0        5     0     0     0    5          NaN\n",
       "1    SSE  1887       0      155     0     0     0  155          NaN\n",
       "2    SSE  1888       0      224    16     0     0  240          NaN\n",
       "3    SSE  1889       0      182    11    92     0  285          NaN\n",
       "4    SSE  1890       0      251    42     0     0  292          NaN"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Read in salmon catch data\n",
    "catch_data = pd.read_csv('https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1')\n",
    "\n",
    "catch_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "b. Use this code cell to make some other preliminary data exploration of your choosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region          object\n",
      "Year             int64\n",
      "Chinook         object\n",
      "Sockeye          int64\n",
      "Coho             int64\n",
      "Pink             int64\n",
      "Chum             int64\n",
      "All              int64\n",
      "notesRegCode    object\n",
      "dtype: object\n",
      "(1708, 9)\n",
      "['SSE' 'NSE' 'YAK' 'GSE' 'BER' 'COP' 'PWS' 'CKI' 'BRB' 'KSK' 'YUK' 'NRS'\n",
      " 'KTZ' 'KOD' 'CHG' 'SOP' 'ALU' 'NOP']\n",
      "[1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899\n",
      " 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913\n",
      " 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927\n",
      " 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941\n",
      " 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955\n",
      " 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969\n",
      " 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983\n",
      " 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997\n",
      " 1883 1884 1885 1878 1879 1880 1881 1882]\n",
      "Region             0\n",
      "Year               0\n",
      "Chinook            0\n",
      "Sockeye            0\n",
      "Coho               0\n",
      "Pink               0\n",
      "Chum               0\n",
      "All                0\n",
      "notesRegCode    1425\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the column names and the class of each column\n",
    "print(catch_data.dtypes)\n",
    "\n",
    "# Print the dimensions of the dataset\n",
    "print(catch_data.shape)\n",
    "\n",
    "# Find the unique values of the `Region` and `Year` columns\n",
    "print(catch_data['Region'].unique())\n",
    "\n",
    "print(catch_data['Year'].unique())\n",
    "\n",
    "# Find the sum of all NA values in each column and print the results\n",
    "na_counts = catch_data.isna().sum()\n",
    "print(na_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "c. Use this markdown cell to explain why you decided to do the exploration in c. and what information you obtained from doing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In the previous step, I chose to look at the names of all the columns and their respective data types so that I could accurately call and manipulate them them later in the activity. IN some cases, functinos won't apply to data of a given class so I will need to know the type of data when I attempt to clean or transform it. I also checked the unique values of the region and year columns to get an idea of the responses that were observed, what to expect, and to see if any years were omitted. Lastly, I checked each column for a sum of all NA values present to ensure that I wasn't missing any data.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 2\n",
    "In the next cell:\n",
    "\n",
    "a. Store the unique values of the `notesRegCode` column in the `notes_unique` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'Includes Yakutat catches' 'Yakutat catch included in No SE AK catch'\n",
      " 'Estimated from canned production, probably sockeye' 'No fishery'\n",
      " 'Bering River catches included in Copper River catches'\n",
      " 'Includes Bering River catches; estimated from canned'\n",
      " 'Includes Bering River catches'\n",
      " 'Coho and pink catch estimated from canned production'\n",
      " 'Includes Bering River; coho and pink estimated fro canned'\n",
      " 'Pink catch estimated from canned'\n",
      " 'Includes Bering River; coho pink and chum estimated from canned'\n",
      " 'Includes Bering River; pink estimated from canned'\n",
      " 'Includes Bering River; pink and chum estimated from canned'\n",
      " 'Includes Copper River catches'\n",
      " 'Includes Copper River catches; coho catch porbably mostly pinks'\n",
      " 'Eshamy District only' 'Estimated from canned; excludes Resurrection Bay'\n",
      " 'Estimated from canned production' 'No Resurrection Bay fishery'\n",
      " 'Resurrection bay contribution estimated from canned production'\n",
      " 'No reported catch'\n",
      " 'Sockeye and pink and 9922 chum from Port Clarence area'\n",
      " 'Chinook and coho and chum estimated from canned production'\n",
      " 'Pink catch includes some chums'\n",
      " 'Pink and chum catch estimated form canned production'\n",
      " 'Pink and chum catch estimated form canned production; from Castle Cp. To E. boundary'\n",
      " 'Estimated from canned production; includes Aleautian Island catches'\n",
      " 'Catches from Unalaksa to Castle Cape'\n",
      " 'Catches included in S. peninsula catches or none']\n"
     ]
    }
   ],
   "source": [
    "#Find the unique values of the `notesRegCode` column and assign it to a variable\n",
    "notes_unique = catch_data['notesRegCode'].unique()\n",
    "print(notes_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "b. Update the dataframe so it doesn't include the `notesRegCode` column. Verify the column is no longer in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove the `notesRegCode` column and  save it to the same variable name\n",
    "catch_data = catch_data.drop(columns = ['notesRegCode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 3\n",
    "Does each column have the expected data type? Use this code cell to obtain this information and write your answer in the next markdown cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the 'Chinook' column is currently classified as object, but the data is numerical. It needs to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region     object\n",
       "Year        int64\n",
       "Chinook    object\n",
       "Sockeye     int64\n",
       "Coho        int64\n",
       "Pink        int64\n",
       "Chum        int64\n",
       "All         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the data types of each column again\n",
    "catch_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 4 \n",
    "The following cell shows a first attempt at updating the `Catch` column to be of data type `int64` instead of `object`. Converting from one data type to another is often called **casting**. \n",
    "\n",
    "To do it we use the [`astype()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.astype.html) method for `pandas.Series`. The `astype()` method does not modify the `pandas.Series` in place.\n",
    "\n",
    "Run the next cell and read the end of the error message closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_data['Catch'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 5 \n",
    "\n",
    "The previous error tells us there is a value 'I' (as in the letter 'I') that could not be converted to integer type.  It turns out the original data set was created from a PDF which was automatically converted into a CSV file and this 'I' vlaue should be 1.\n",
    "\n",
    "In the next cell find the row(s) causing this issue. Show the filtered row(s) as the output. Store your answer in the `catch_I` variable. `catch_I` should have one observation and contain the following columns: Region, Year, Species, Catch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catch_I = ...\n",
    "catch_I "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6\n",
    "In the next cell:\n",
    "\n",
    "1. Update the value of I to 1.\n",
    "2. Access the row you updated to verify the value was changed and store this singe row in the `catch_1` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catch_1 = ...\n",
    "catch_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7\n",
    "In the next cell:\n",
    "\n",
    "1. Update the `Catch` column in `catch_data` to be of type `int64`.\n",
    "2. Confirm you have updated the data type. Store the type of the `catch` column in the `catch_column_type` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catch_column_type = ...\n",
    "catch_column_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 8\n",
    "Create a data frame with the average salmon catch per region. HINT: use `groupby()`. Store your dataframe in new variable called `avg_region`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_region = ...\n",
    "avg_region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 9 \n",
    "\n",
    "Use the dataframe you created in 8 to make a bar graph of the estimated average salmon catches by region from 1878 to 1997. The bars in the graph should be ordered by magnitude (increasing or decreasing is ok). Add a title  to your graph and update the axes labels if needed (check the units for the salmon catch). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 10\n",
    "\n",
    "Write a brief description with key takeaways from the plot. Your answer shuld use the complete names for the management areas instead of their codes. You can find what each code stands for in the [original data repository](https://knb.ecoinformatics.org/view/df35b.304.2#df35b.303.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 11\n",
    "\n",
    "Collect all the relevant code into the first blank cell of the notebook titled \"COMPLETE WORKFLOW\". This single cell will have the end-to-end workflow: from importing libraries and loading the data, to producing the graph. The *only* ouput of this cell should be the graph you produced in the previous exercise. Further guidance on what to include in this final workflow is in the [assignment rubric](https://docs.google.com/document/d/1x0BoU6IH4cnOR1-n7i9CYQ9wUC37yDpYlQ4j6rCfcsU/edit?tab=t.0)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d9c35c8115062f8f91024dabb290da02183a26877d6f60ace8c62884141c720"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
